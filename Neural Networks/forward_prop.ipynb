{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9e925385-6756-4600-bbf8-208fe17e3b1c",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<p style=\"float:right;\"><i>Created By Maroyi Bisoka on 01/02/2025</i></p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1320,
   "id": "de731ba6-a2a3-47d4-a279-07f9d897372e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3855fecf-82f3-478b-97ff-442f4cab953f",
   "metadata": {},
   "source": [
    "**A dense layer**, also known as a fully connected layer, is a type of neural network layer where every neuron in the layer is connected to every neuron in the previous layer. This connectivity allows each neuron to receive input from all neurons in the preceding layer."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "a650d6ea-f31f-473d-b426-086aec08bf35",
   "metadata": {},
   "source": [
    "<img src=\"./neural_network_img.png\" style=\"width: 400px; height: auto;\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1323,
   "id": "225525be-454b-4ae3-a8f1-836e8d9639e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Activation function --> Sigmoid \n",
    "def sigmoid(z):\n",
    "    g = 1 / (1 + np.exp(-z))\n",
    "    return g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1324,
   "id": "9c1543fb-83e4-489a-a912-f310041b96a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the activation function of each neuron within a single Layer\n",
    "def dense(a_in, W, b, activation_function):\n",
    "    no_neurons = W.shape[1]\n",
    "    a_out = np.zeros(no_neurons)\n",
    "    for j in range(no_neurons):\n",
    "        w = W[:, j]\n",
    "        z = np.dot(a_in, w) + b[j]\n",
    "        a_out[j] = activation_function(z)\n",
    "    return a_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1325,
   "id": "26b40cfe-835e-4be6-9120-f08fdbbf76f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the forward propagation algorithm\n",
    "def sequential(x, W_list, b_list, activation_function):\n",
    "    no_layers = len(W_list)\n",
    "    a_in  = x\n",
    "    for i in range(no_layers):\n",
    "        a_out = dense(a_in, W_list[i], b_list[i], activation_function)\n",
    "        a_in = a_out\n",
    "    return a_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1326,
   "id": "cf178a24-6a22-4c55-b3e0-136a8edef984",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-63,  40],\n",
       "       [-28,  37],\n",
       "       [ 33, -21],\n",
       "       [ 92,  44],\n",
       "       [ 29, -29]])"
      ]
     },
     "execution_count": 1326,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Random initialization of the value of x\n",
    "np.random.seed(1)\n",
    "X_test = np.random.randint(-100, 100, size=(5,2))\n",
    "X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1327,
   "id": "55bc0c0d-c8ce-43b9-a8c3-136432725cff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random initialization for the parameters W and b\n",
    "\n",
    "l1_shape = (2,2) # layer1_shape (number of W in a single neurons, number of neurons)\n",
    "l2_shape = (2,1) # layer2_shape (number of W in a single neurons, number of neurons)\n",
    "\n",
    "np.random.seed(10) # used to generate same random number\n",
    "W1 = np.random.rand(l1_shape[0], l1_shape[1])\n",
    "\n",
    "np.random.seed(20)\n",
    "b1 =  np.random.rand(l1_shape[1])\n",
    "\n",
    "np.random.seed(30) \n",
    "W2 = np.random.rand(l2_shape[0], l2_shape[1])\n",
    "\n",
    "np.random.seed(40) \n",
    "b2 = np.random.rand(l2_shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1328,
   "id": "f37d896c-2e53-4820-8b3f-2a3631fa056d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[0.77132064, 0.02075195],\n",
       "        [0.63364823, 0.74880388]]),\n",
       " array([0.5881308 , 0.89771373]))"
      ]
     },
     "execution_count": 1328,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "W1, b1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1329,
   "id": "81047907-71b6-4619-a40e-99900cd918ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "W1_1:  [0.77132064 0.63364823]\n",
      "W1_2:  [0.02075195 0.74880388]\n"
     ]
    }
   ],
   "source": [
    "# W1 means all the w for layer 1\n",
    "# W1_1 means all the w for the 1st layer 1st neuron\n",
    "W1_1 = W1[:, 0]\n",
    "print('W1_1: ', W1_1)\n",
    "# W1_2 means all the w for the 1st layer 2nd neuron\n",
    "W1_2= W1[:, 1]\n",
    "print('W1_2: ', W1_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1330,
   "id": "718b750b-8765-40d5-aeaa-8ccd2e9e995c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[0.64414354],\n",
       "        [0.38074849]]),\n",
       " array([0.40768703]))"
      ]
     },
     "execution_count": 1330,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "W2, b2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1331,
   "id": "5280b6c2-ad83-4bf8-b523-d63bdd80dac2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "W2_1:  [0.64414354 0.38074849]\n"
     ]
    }
   ],
   "source": [
    "# W2 means all the w for layer 2\n",
    "# W2_1 means all the w for the 2nd layer 1st neuron\n",
    "W2_1 = W2[:, 0]\n",
    "print('W2_1: ', W2_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb2b5f2a-f763-4e4d-b49a-58878e3b2c4c",
   "metadata": {},
   "source": [
    "\n",
    "<br />\n",
    "<hr />\n",
    "\n",
    "**NB**: All of the rows of a specific col within a W matrix specify the w's of a specific neuron.\n",
    "\n",
    "For example: \n",
    "- If we're looking for the w's of the 1st layer 1st neuron --> **W1[: , 0]** we used **':'** for the row to get all the row and **'0'** for the column since python indexing start from zero (neuron 1 at index 0, neuron 2 at index 1, and so on).\n",
    "- If we're looking for the w's of the 1st layer 2nd neuron  --> **W1[: , 1]**\n",
    "- If we're looking for the w's of the 2nd layer 1st neuron  --> **W2[: , 0]**\n",
    "- If we're looking for the b of the 1st layer 2nd neuron  --> **b1[1]**\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1333,
   "id": "3f81575a-292f-4472-8c20-e19754c30fc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "W_list = [W1, W2]\n",
    "b_list = [b1, b2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1334,
   "id": "ee7d42c9-f927-4f99-b9bf-17d0c49a952a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.68749531])"
      ]
     },
     "execution_count": 1334,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Running Forward propagation for a single test example\n",
    "sequential(X_test[0], W_list, b_list, sigmoid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1335,
   "id": "2c85fa39-176d-4755-b5f6-1e5d2619a03a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(X_test, W_list, b_list, sigmoid):\n",
    "    m = X_test.shape[0]\n",
    "    a_out = np.zeros(m)\n",
    "    for i in range(m):\n",
    "        a_out[i] = sequential(X_test[i], W_list, b_list, sigmoid)\n",
    "    return a_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1336,
   "id": "95e5383b-1c73-4067-8ace-1712bf32072a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Running Forward propagation for whole test examples\n",
    "a_out = predict(X_test, W_list, b_list, sigmoid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1337,
   "id": "a1109ec1-6bbd-4bad-9700-dc447fb42712",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.68749531, 0.79911181, 0.74112595, 0.80730284, 0.73987059])"
      ]
     },
     "execution_count": 1337,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a_out"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5fcd6b1-3e8f-4977-818b-628f45ad1ee0",
   "metadata": {},
   "source": [
    "## Checking with Tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1339,
   "id": "bdfc6c1a-05d9-460e-89fe-759a4707bdd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1340,
   "id": "1d58d39b-30f0-40f3-8067-cba174e4639e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential(\n",
    "    [\n",
    "        tf.keras.Input(shape=(2,)), # means number of features\n",
    "        Dense(2, activation='sigmoid', name = 'layer1'), # (Number of neurons, Activation function, Name of the Layer)\n",
    "        Dense(1, activation='sigmoid', name = 'layer2'),  # (Number of neurons, Activation function, Name of the Layer)\n",
    "     ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1341,
   "id": "cf93ddb1-07db-4c15-b1e3-aac3878e4136",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_17\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_17\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ layer1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>)              │             <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ layer2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │             <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ layer1 (\u001b[38;5;33mDense\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2\u001b[0m)              │             \u001b[38;5;34m6\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ layer2 (\u001b[38;5;33mDense\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │             \u001b[38;5;34m3\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">9</span> (36.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m9\u001b[0m (36.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">9</span> (36.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m9\u001b[0m (36.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1342,
   "id": "b2e51c41-91bb-4a80-a54f-b9c19c4caf51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "W of layer1 (W1): \n",
      "[[0.77132064 0.02075195]\n",
      " [0.6336482  0.74880385]]\n",
      "-------------------------\n",
      "b of layer1 (b1): \n",
      "[0.5881308 0.8977137]\n"
     ]
    }
   ],
   "source": [
    "# Setting W and b for layer 1\n",
    "model.get_layer('layer1').set_weights([W1, b1])\n",
    "print('W of layer1 (W1): ')\n",
    "print(model.get_layer('layer1').weights[0].numpy())\n",
    "print('-------------------------')\n",
    "print('b of layer1 (b1): ')\n",
    "print(model.get_layer('layer1').weights[1].numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1343,
   "id": "d323be90-207f-4cf2-aff8-2a83e03e941a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "W of layer2 (W2): \n",
      "[[0.6441435 ]\n",
      " [0.38074848]]\n",
      "-------------------------\n",
      "b of layer2 (b2): \n",
      "[0.40768704]\n"
     ]
    }
   ],
   "source": [
    "# Setting W and b for layer 2\n",
    "model.get_layer('layer2').set_weights([W2, b2])\n",
    "print('W of layer2 (W2): ')\n",
    "print(model.get_layer('layer2').weights[0].numpy())\n",
    "print('-------------------------')\n",
    "print('b of layer2 (b2): ')\n",
    "print(model.get_layer('layer2').weights[1].numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1344,
   "id": "2fddd15a-17dc-4366-a08c-90fc664ba98c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.68749535],\n",
       "       [0.7991118 ],\n",
       "       [0.74112594],\n",
       "       [0.80730283],\n",
       "       [0.7398706 ]], dtype=float32)"
      ]
     },
     "execution_count": 1344,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Tensorflow prediction\n",
    "model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1345,
   "id": "faf47003-6641-4d91-b33b-8073aa526031",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.68749531, 0.79911181, 0.74112595, 0.80730284, 0.73987059])"
      ]
     },
     "execution_count": 1345,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Our own implemetation prediction\n",
    "a_out"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
